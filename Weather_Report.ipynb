{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Beautiful day, isn't it?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Obvserving shifts in Global and Local Temperature since 1750\n",
    "\n",
    "## Outline\n",
    "* Extracting Data from a SQL database\n",
    "* Importing and reshaping a dataset for analysis\n",
    "* Calculating a moving average\n",
    "* Creating and interpreting a simple data visualization \n",
    "\n",
    "### 1)Extracting data from a SQL database:\n",
    "##### QUERY.sql\n",
    "The data that we are interested in is contained in two tables. We can pull all of the relevant information in a single SQL query by performing a union of the desired records from each of the tables.\n",
    "*Note, since a union requires output columns to match on both tables, we will create the 'city' column that is missing in the global table. \n",
    "\n",
    "*Also note: We are not actually connected to the database here, nor are we incorporating SQL functionality in this notebook, so the following query is for reference purposes only."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#SELECT year, city, avg_temp\n",
    "#FROM city_data\n",
    "#WHERE city = 'Baltimore'\n",
    "#UNION ALL\n",
    "#SELECT year, 'global' AS city, avg_temp \n",
    "#FROM global_data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We have been provided an easy-access tool which allows us to export the data returned by our query as a .csv file, RESULTS.csv\n",
    "\n",
    "### 2) Importing the data into Python and reshaping it for analysis\n",
    "##### format.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Reading the data from the CSV file that our SQL query generated into a Pandas DataFrame\n",
    "raw = pd.read_csv('RESULTS.csv')\n",
    "\n",
    "# Taking a look:\n",
    "print(raw.head())\n",
    "print(raw.tail())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We now have the data we need in a Pandas DataFrame. Let's make it better by reshaping it so that local and global temp are both contained within each observation, indexed by year.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reshaping the Dataframe \n",
    "shaped = pd.pivot_table(raw, values = 'avg_temp', index= 'year', columns= 'city')\n",
    "\n",
    "#Take another look:\n",
    "print(shaped.head(10))\n",
    "print(shaped.tail(10))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We now have our global and local temperatures in their own separate columns, and the data is indexed by year. \n",
    "\n",
    "There is missing data at the head and tail of the dataframe and many are missing in both columns. We can safely ignore those years where data is missing since there are so few, so lets trim the dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#trimming the start and end years where data is missing \n",
    "almost_tidy = shaped.loc[1750:2013]\n",
    "\n",
    "#making sure it worked\n",
    "print(almost_tidy.head(5))\n",
    "print(almost_tidy.tail(5))\n",
    "\n",
    "#check for and locate any other missing values\n",
    "print(almost_tidy.isnull().any())\n",
    "print(almost_tidy[almost_tidy.isnull().any(axis=1)])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Great, our head and tail are clean, and we only have one missing value. Let's look more closely to see if that value could be easily imputed: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "almost_tidy.loc[1775:1785]['Baltimore']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is an odd result. Not only is the value missing in 1780, it is lower than usual in 1778 and extremely low in 1780. Because of this I don't want to backfill or forward fill. I also don't want to use a measure of centrality because of the presence of outliers. What I will do is use a hybrid approach, replacing the temp at 1780 with the temp from 1778, creating a sort of \"V\" shape in the data. \n",
    "\n",
    "This is an admittedly crude and unscientific approach, but since we're already planning to use moving averages, this shouldn't taint our final analysis. We're going to leave in the outlier because we have no way of telling (for now) whether it is a mistake or if there was some sort of strange weather phenomenon that year in Baltimore. This would be a question for further research!\n",
    "\n",
    "(we're finally done cleaning our data, so let's rename it too)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "almost_tidy.loc[1780]['Baltimore'] = almost_tidy.loc[1778]['Baltimore']\n",
    "\n",
    "tidy = almost_tidy.loc[:]\n",
    "del almost_tidy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3) Calculating the moving average\n",
    "##### analyze.py\n",
    "\n",
    "Data can be 'smoothed' by calculating a moving average. This reduces the amplitude of unit-wise fluctuations by replacing actual observation values with the average of multiple observation values over a certain range. \n",
    "\n",
    "We are going to do this in python by writing a function which will allow us to define how large of a range we want to use to calculate our averages. A higher range or 'width' will produce a 'smoother' output. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    " \n",
    "def run_avg(data, width, bfill = True):\n",
    "    output = []\n",
    "    if width > len(data)/2:\n",
    "        return print(\"Width too large. Please select a value less than \" \\\n",
    "                     + str(len(data)/4) + \".\")\n",
    "            #^^^ This is a safeguard against selecting a range that is too large.\n",
    "    for i in range(0,(len(data))):\n",
    "        if i < width-1:\n",
    "            if bfill:\n",
    "                output.append(round(np.mean(data[0:width-1]), 2))\n",
    "            # Backfills with first calculation so output data matches length of input data.\n",
    "            continue\n",
    "        else:\n",
    "            output.append(round(np.mean(data[i-width+1:i]), 2))\n",
    "    return np.array(output)\n",
    "    # Returns running average as ndarray"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that we have a way of calculating moving averages on a series, lets apply this function to the data in our dataframe. We will do this for the local temp data and the global temp data, and then will add these moving averages to our existing dataframe to keep everything in one place. For this exercise, we will be using a 10-year moving average. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "local_avg_10 = run_avg(tidy['Baltimore'], 10)\n",
    "global_avg_10 = run_avg(tidy['global'], 10)\n",
    "\n",
    "tidy.loc[:, 'Balt_avg'] = local_avg_10\n",
    "tidy.loc[:, 'global_avg'] = global_avg_10\n",
    "\n",
    "#as usual, let's take a look:\n",
    "print(tidy[4:16])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Awesome!\n",
    "\n",
    "### 4) Creating and interpreting a simple data visualization\n",
    "\n",
    "Now that we have all of our data in its final format, we want to explore it visually. \n",
    "\n",
    "Before we look at trends, I'd like to just check and see how much of an effect our moving average had on how the data looks. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "tidy.plot(subplots=True, lw=2, title='Smoothed vs Unsmoothed trendlines')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can see, even just at a glance, that our moving average had the intended effect of 'smoothing' the data. We also see that our outlier at 1778 has a pretty significant effect on the moving average. Actually, using a moving average can, in a way, strengthen the effect of an outlier because that outlier will be used in multiple average calculations rather than just in a single observation! We would want to address this if we were going to proceed further with our analysis.\n",
    "\n",
    "Lets look more closely at the smoothed data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tidy[['Balt_avg','global_avg']].plot(lw=4, title='Temperature 1750-2013 \\\n",
    "(10-year moving avg)').set_ylabel('Temperature')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "From this, we can observe the following: <br/>\n",
    "1) The temperature in Baltimore has been significantly higher than the global average temperature for at least the past 250 years. This makes sense because Baltimore is relatively close to the equator. <br/>\n",
    "2) Temperatures in Baltimore and in the world on average have been increasing. While this seems pretty clear, we can verify by plotting lines of best fit. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Calculating the slope and y-intercept of each line of best fit. \n",
    "mbalt, bbalt = np.polyfit(tidy.index, tidy['Balt_avg'], 1) \n",
    "mglob, bglob = np.polyfit(tidy.index, tidy['global_avg'], 1)\n",
    "\n",
    "#superimposing the linear regression onto the data plot\n",
    "tidy[['Balt_avg','global_avg']].plot(lw=4, title='Temperature 1750-2013 \\\n",
    "(10-year moving avg)').set_ylabel('Temperature')\n",
    "plt.plot(tidy.index, mglob*tidy.index+bglob, label='global', lw=2)\n",
    "plt.plot(tidy.index, mbalt*tidy.index+bbalt, label='Baltimore', lw=2)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As this demonstrates, the temperature is trending upwards for both local and global data. This also brings us to:<br/>\n",
    "3) The Baltimore line is steeper than the global line which means that avg temperature has been increasing more rapidly for Baltimore than it has for the world as a whole (at least during the years between 1750 and 2013) <br/>\n",
    "4) The final (and perhaps most interesting, at least for someone who is interested in Baltimore!) observation is that, for the most part, the general trends of the temperatures in Baltimore closely matches that of the world, but about 3 degrees hotter. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
